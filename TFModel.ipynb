{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOwUoOhrPu48yxfnxZvjr9/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TheRadDani/TensorFlow-functional-api/blob/main/TFModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dC1ilJ16YH6l"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "inputs = tf.keras.Input(shape=(3,))\n",
        "x = tf.keras.layers.Dense(4, activation=tf.nn.relu)(inputs)\n",
        "outputs = tf.keras.layers.Dense(5, activation=tf.nn.softmax)(x)\n",
        "model = tf.keras.Model(inputs=inputs, outputs=outputs)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = keras.Input(shape=(None, None, 3))\n",
        "processed = keras.layers.RandomCrop(width=32, height=32)(inputs)\n",
        "conv = keras.layers.Conv2D(filters=2, kernel_size=3)(processed)\n",
        "pooling = keras.layers.GlobalAveragePooling2D()(conv)\n",
        "feature = keras.layers.Dense(10)(pooling)\n",
        "\n",
        "full_model = keras.Model(inputs, feature)\n",
        "backbone = keras.Model(processed, conv)\n",
        "activations = keras.Model(conv, feature)"
      ],
      "metadata": {
        "id": "ixVXHOksZxmo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Subclassing the model"
      ],
      "metadata": {
        "id": "VALWx4BSaYAG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class MyModel(tf.keras.Model):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.dense1 = tf.keras.layers.Dense(4, activation=tf.nn.relu)\n",
        "    self.dense2 = tf.keras.layers.Dense(5, activation=tf.nn.softmax)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    x = self.dense1(inputs)\n",
        "    return self.dense2(x)\n",
        "\n",
        "model = MyModel()"
      ],
      "metadata": {
        "id": "cWmha6YeaaI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class MyModel(tf.keras.Model):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.dense1 = tf.keras.layers.Dense(4, activation=tf.nn.relu)\n",
        "    self.dense2 = tf.keras.layers.Dense(5, activation=tf.nn.softmax)\n",
        "    self.dropout = tf.keras.layers.Dropout(0.5)\n",
        "\n",
        "  def call(self, inputs, training=False):\n",
        "    x = self.dense1(inputs)\n",
        "    if training:\n",
        "      x = self.dropout(x, training=training)\n",
        "    return self.dense2(x)\n",
        "\n",
        "model = MyModel()"
      ],
      "metadata": {
        "id": "9eonhMZDa5CA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "inputs = tf.keras.layers.Input(shape=(3,))\n",
        "outputs = tf.keras.layers.Dense(2)(inputs)\n",
        "model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
        "model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\"])\n",
        "batch_size = 3000 # Set the batch size\n",
        "history = model.fit(np.random.rand(batch_size,3),np.zeros((batch_size,2)),epochs = 10, verbose=2)\n",
        "model.metrics_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnwgwHCDc7UE",
        "outputId": "a6904970-29f8-456e-e572-c4f2ec7df632"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "94/94 - 1s - loss: 0.1616 - mae: 0.3257 - 849ms/epoch - 9ms/step\n",
            "Epoch 2/10\n",
            "94/94 - 0s - loss: 0.1279 - mae: 0.2904 - 186ms/epoch - 2ms/step\n",
            "Epoch 3/10\n",
            "94/94 - 0s - loss: 0.1043 - mae: 0.2624 - 198ms/epoch - 2ms/step\n",
            "Epoch 4/10\n",
            "94/94 - 0s - loss: 0.0851 - mae: 0.2370 - 191ms/epoch - 2ms/step\n",
            "Epoch 5/10\n",
            "94/94 - 0s - loss: 0.0689 - mae: 0.2135 - 188ms/epoch - 2ms/step\n",
            "Epoch 6/10\n",
            "94/94 - 0s - loss: 0.0553 - mae: 0.1911 - 186ms/epoch - 2ms/step\n",
            "Epoch 7/10\n",
            "94/94 - 0s - loss: 0.0439 - mae: 0.1703 - 192ms/epoch - 2ms/step\n",
            "Epoch 8/10\n",
            "94/94 - 0s - loss: 0.0344 - mae: 0.1509 - 199ms/epoch - 2ms/step\n",
            "Epoch 9/10\n",
            "94/94 - 0s - loss: 0.0267 - mae: 0.1329 - 189ms/epoch - 2ms/step\n",
            "Epoch 10/10\n",
            "94/94 - 0s - loss: 0.0205 - mae: 0.1162 - 196ms/epoch - 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['loss', 'mae']"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "inputs = tf.keras.layers.Input(shape=(10,))\n",
        "x = tf.keras.layers.Dense(64, activation='relu')(inputs)\n",
        "x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
        "outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "@tf.function\n",
        "def train_step(inputs, labels):\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = model(inputs, training=True)\n",
        "        loss = tf.keras.losses.BinaryCrossentropy()(labels, predictions)\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "    train_loss(loss)\n",
        "    train_accuracy(labels, predictions)\n",
        "\n",
        "# Generate 1000 samples of input data with 10 features each\n",
        "x_train = np.random.randn(1000, 10)\n",
        "\n",
        "# Generate 1000 random binary labels for the classification task\n",
        "y_train = np.random.randint(2, size=1000)\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(32)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.BinaryAccuracy(name='train_accuracy')\n",
        "\n",
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "    for step, (inputs, labels) in enumerate(train_dataset):\n",
        "        train_step(inputs, labels)\n",
        "    print('Epoch: {}, Loss: {}, Accuracy: {}'.format(epoch+1, train_loss.result(), train_accuracy.result()))\n",
        "    train_loss.reset_states()\n",
        "    train_accuracy.reset_states()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fMZTsT-gfbX",
        "outputId": "a15fd388-589a-4320-aea3-47990005f08a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Loss: 0.696258544921875, Accuracy: 0.527999997138977\n",
            "Epoch: 2, Loss: 0.682414174079895, Accuracy: 0.5600000023841858\n",
            "Epoch: 3, Loss: 0.6750593781471252, Accuracy: 0.5929999947547913\n",
            "Epoch: 4, Loss: 0.6698946952819824, Accuracy: 0.5979999899864197\n",
            "Epoch: 5, Loss: 0.6649953722953796, Accuracy: 0.6019999980926514\n",
            "Epoch: 6, Loss: 0.65837162733078, Accuracy: 0.6290000081062317\n",
            "Epoch: 7, Loss: 0.651261568069458, Accuracy: 0.6359999775886536\n",
            "Epoch: 8, Loss: 0.653340756893158, Accuracy: 0.6140000224113464\n",
            "Epoch: 9, Loss: 0.644133985042572, Accuracy: 0.652999997138977\n",
            "Epoch: 10, Loss: 0.6406399607658386, Accuracy: 0.6470000147819519\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "subset = train_dataset.take(1)\n",
        "\n",
        "# Convert the dataset to a NumPy array\n",
        "x, y = next(iter(subset))\n",
        "x = x.numpy()\n",
        "y = y.numpy()\n",
        "print(x.shape)\n",
        "print(y.size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2_2alxyi_Qj",
        "outputId": "f637d494-2071-4b1f-d93d-13635db2712f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 10)\n",
            "32\n"
          ]
        }
      ]
    }
  ]
}