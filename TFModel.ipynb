{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNyyaCuS5sbjqVOoC5X1SFt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TheRadDani/TensorFlow-functional-api/blob/main/TFModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dC1ilJ16YH6l"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "inputs = tf.keras.Input(shape=(3,))\n",
        "x = tf.keras.layers.Dense(4, activation=tf.nn.relu)(inputs)\n",
        "outputs = tf.keras.layers.Dense(5, activation=tf.nn.softmax)(x)\n",
        "model = tf.keras.Model(inputs=inputs, outputs=outputs)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = keras.Input(shape=(None, None, 3))\n",
        "processed = keras.layers.RandomCrop(width=32, height=32)(inputs)\n",
        "conv = keras.layers.Conv2D(filters=2, kernel_size=3)(processed)\n",
        "pooling = keras.layers.GlobalAveragePooling2D()(conv)\n",
        "feature = keras.layers.Dense(10)(pooling)\n",
        "\n",
        "full_model = keras.Model(inputs, feature)\n",
        "backbone = keras.Model(processed, conv)\n",
        "activations = keras.Model(conv, feature)"
      ],
      "metadata": {
        "id": "ixVXHOksZxmo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Subclassing the model"
      ],
      "metadata": {
        "id": "VALWx4BSaYAG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class MyModel(tf.keras.Model):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.dense1 = tf.keras.layers.Dense(4, activation=tf.nn.relu)\n",
        "    self.dense2 = tf.keras.layers.Dense(5, activation=tf.nn.softmax)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    x = self.dense1(inputs)\n",
        "    return self.dense2(x)\n",
        "\n",
        "model = MyModel()"
      ],
      "metadata": {
        "id": "cWmha6YeaaI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class MyModel(tf.keras.Model):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.dense1 = tf.keras.layers.Dense(4, activation=tf.nn.relu)\n",
        "    self.dense2 = tf.keras.layers.Dense(5, activation=tf.nn.softmax)\n",
        "    self.dropout = tf.keras.layers.Dropout(0.5)\n",
        "\n",
        "  def call(self, inputs, training=False):\n",
        "    x = self.dense1(inputs)\n",
        "    if training:\n",
        "      x = self.dropout(x, training=training)\n",
        "    return self.dense2(x)\n",
        "\n",
        "model = MyModel()"
      ],
      "metadata": {
        "id": "9eonhMZDa5CA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "inputs = tf.keras.layers.Input(shape=(3,))\n",
        "outputs = tf.keras.layers.Dense(2)(inputs)\n",
        "model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
        "model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\"],jit_compile=True)\n",
        "batch_size = 3000 # Set the batch size\n",
        "history = model.fit(np.random.rand(batch_size,3),np.zeros((batch_size,2)),epochs = 10, verbose=2)\n",
        "model.metrics_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnwgwHCDc7UE",
        "outputId": "7c244e49-121c-4dc8-95a5-4820360e7eac"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "94/94 - 3s - loss: 0.0927 - mae: 0.2453 - 3s/epoch - 27ms/step\n",
            "Epoch 2/10\n",
            "94/94 - 0s - loss: 0.0713 - mae: 0.2154 - 222ms/epoch - 2ms/step\n",
            "Epoch 3/10\n",
            "94/94 - 0s - loss: 0.0562 - mae: 0.1914 - 209ms/epoch - 2ms/step\n",
            "Epoch 4/10\n",
            "94/94 - 0s - loss: 0.0439 - mae: 0.1692 - 216ms/epoch - 2ms/step\n",
            "Epoch 5/10\n",
            "94/94 - 0s - loss: 0.0339 - mae: 0.1487 - 212ms/epoch - 2ms/step\n",
            "Epoch 6/10\n",
            "94/94 - 0s - loss: 0.0259 - mae: 0.1298 - 241ms/epoch - 3ms/step\n",
            "Epoch 7/10\n",
            "94/94 - 0s - loss: 0.0195 - mae: 0.1126 - 208ms/epoch - 2ms/step\n",
            "Epoch 8/10\n",
            "94/94 - 0s - loss: 0.0145 - mae: 0.0971 - 313ms/epoch - 3ms/step\n",
            "Epoch 9/10\n",
            "94/94 - 0s - loss: 0.0106 - mae: 0.0831 - 245ms/epoch - 3ms/step\n",
            "Epoch 10/10\n",
            "94/94 - 0s - loss: 0.0076 - mae: 0.0706 - 211ms/epoch - 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['loss', 'mae']"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "inputs = tf.keras.layers.Input(shape=(10,))\n",
        "x = tf.keras.layers.Dense(64, activation='relu')(inputs)\n",
        "x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
        "outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "@tf.function\n",
        "def train_step(inputs, labels):\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = model(inputs, training=True)\n",
        "        loss = tf.keras.losses.BinaryCrossentropy()(labels, predictions)\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "    train_loss(loss)\n",
        "    train_accuracy(labels, predictions)\n",
        "\n",
        "# Generate 1000 samples of input data with 10 features each\n",
        "x_train = np.random.randn(1000, 10)\n",
        "\n",
        "# Generate 1000 random binary labels for the classification task\n",
        "y_train = np.random.randint(2, size=1000)\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(32)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.BinaryAccuracy(name='train_accuracy')\n",
        "\n",
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "    for step, (inputs, labels) in enumerate(train_dataset):\n",
        "        train_step(inputs, labels)\n",
        "    print('Epoch: {}, Loss: {}, Accuracy: {}'.format(epoch+1, train_loss.result(), train_accuracy.result()))\n",
        "    train_loss.reset_states()\n",
        "    train_accuracy.reset_states()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fMZTsT-gfbX",
        "outputId": "a15fd388-589a-4320-aea3-47990005f08a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Loss: 0.696258544921875, Accuracy: 0.527999997138977\n",
            "Epoch: 2, Loss: 0.682414174079895, Accuracy: 0.5600000023841858\n",
            "Epoch: 3, Loss: 0.6750593781471252, Accuracy: 0.5929999947547913\n",
            "Epoch: 4, Loss: 0.6698946952819824, Accuracy: 0.5979999899864197\n",
            "Epoch: 5, Loss: 0.6649953722953796, Accuracy: 0.6019999980926514\n",
            "Epoch: 6, Loss: 0.65837162733078, Accuracy: 0.6290000081062317\n",
            "Epoch: 7, Loss: 0.651261568069458, Accuracy: 0.6359999775886536\n",
            "Epoch: 8, Loss: 0.653340756893158, Accuracy: 0.6140000224113464\n",
            "Epoch: 9, Loss: 0.644133985042572, Accuracy: 0.652999997138977\n",
            "Epoch: 10, Loss: 0.6406399607658386, Accuracy: 0.6470000147819519\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "subset = train_dataset.take(1)\n",
        "\n",
        "# Convert the dataset to a NumPy array\n",
        "x, y = next(iter(subset))\n",
        "x = x.numpy()\n",
        "y = y.numpy()\n",
        "print(x.shape)\n",
        "print(y.size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2_2alxyi_Qj",
        "outputId": "f637d494-2071-4b1f-d93d-13635db2712f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 10)\n",
            "32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "\n",
        "  def __init__(self, *args, **kwargs):\n",
        "    super(MyModel, self).__init__(*args, **kwargs)\n",
        "    self.loss_tracker = tf.keras.metrics.Mean(name='loss')\n",
        "\n",
        "  def compute_loss(self, x, y, y_pred, sample_weight):\n",
        "    l2_loss = tf.reduce_sum([tf.nn.l2_loss(w) for w in self.trainable_variables])\n",
        "    loss = tf.reduce_mean(tf.math.squared_difference(y_pred, y)) + l2_loss\n",
        "    loss += tf.add_n(self.losses)\n",
        "    self.loss_tracker.update_state(loss)\n",
        "    return loss\n",
        "\n",
        "  def reset_metrics(self):\n",
        "    self.loss_tracker.reset_states()\n",
        "\n",
        "  @property\n",
        "  def metrics(self):\n",
        "    return [self.loss_tracker]\n",
        "\n",
        "tensors = tf.random.uniform((10, 10)), tf.random.uniform((10,))\n",
        "dataset = tf.data.Dataset.from_tensor_slices(tensors).repeat().batch(1)\n",
        "\n",
        "inputs = tf.keras.layers.Input(shape=(10,), name='my_input')\n",
        "outputs = tf.keras.layers.Dense(10)(inputs)\n",
        "model = MyModel(inputs, outputs)\n",
        "model.add_loss(tf.reduce_sum(outputs))\n",
        "\n",
        "optimizer = tf.keras.optimizers.SGD()\n",
        "model.compile(optimizer, loss='mse', steps_per_execution=10)\n",
        "model.fit(dataset, epochs=2, steps_per_epoch=10)\n",
        "print('My custom loss: ', model.loss_tracker.result().numpy())\n",
        "[x.result() for x in model.metrics]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5UQEYQxBel0",
        "outputId": "04026c44-2c93-4914-81be-1c3f07f30969"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "10/10 [==============================] - 1s 78ms/step - loss: 5.6903\n",
            "Epoch 2/2\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.3269\n",
            "My custom loss:  2.326882\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor: shape=(), dtype=float32, numpy=2.326882>]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    }
  ]
}